{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breakout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOo7JE8Dgt0IX9hqcWXLxGv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neloy262/Reinforcement_Learning/blob/master/Breakout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av9tTSze2sby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from IPython import display"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTzNqsWj2-rw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b89f808-4b36-4bb0-cffd-071ec60f0b88"
      },
      "source": [
        "env=gym.make('BreakoutDeterministic-v4')\n",
        "rgb_weights = [0.2989, 0.5870, 0.1140]\n",
        "print(env.action_space.n)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdzkVXc03UPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(img):\n",
        "  img=np.dot(img[...,:3], rgb_weights)\n",
        "  img=img[::2,::2]\n",
        "  img=img[16:98]\n",
        "  return img\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PELGBs2l3Pco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "222699d9-0c74-45dd-b4cf-b6390edf3625"
      },
      "source": [
        "state=env.reset()\n",
        "state=np.array(state)\n",
        "action=env.action_space.sample()\n",
        "state1, reward, done, info=env.step(action)\n",
        "state2, reward, done, info=env.step(action)\n",
        "state3, reward, done, info=env.step(action)\n",
        "state4, reward, done, info=env.step(action)\n",
        "state1=preprocess(state1)\n",
        "state2=preprocess(state2)\n",
        "state3=preprocess(state3)\n",
        "state4=preprocess(state4)\n",
        "arr=np.array([state1,state2,state3,state4])\n",
        "newArr=np.stack(arr,axis=2)\n",
        "print(newArr.shape)\n",
        "# plt.imshow(newArr[1], cmap=plt.get_cmap(\"gray\"))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(82, 80, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_9oMEOG4nim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c8abc04-d7ff-4058-df8d-b632dc1fb0f5"
      },
      "source": [
        "state=env.reset()\n",
        "done=False\n",
        "while not done:\n",
        "  #  plt.imshow(env.render(mode='rgb_array'))\n",
        "  #  display.display(plt.gcf())    \n",
        "  #  display.clear_output(wait=True)\n",
        "   action=env.action_space.sample()\n",
        "   state, reward, done, info=env.step(action) # take a random action\n",
        "   print(done)\n",
        "display.set_matplotlib_close\n",
        "env.close()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UxvKIvTDBoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self,state_size,action_size):\n",
        "        self.state_size=state_size\n",
        "        self.action_size=action_size\n",
        "        self.memory=deque(maxlen=2000)\n",
        "        self.gamma=0.95\n",
        "        self.epsilon=1.0\n",
        "        self.epsilon_decay=0.995\n",
        "        self.epsilon_min=0.01\n",
        "        self.learning_rate=0.001\n",
        "        self.model=self.build_model()\n",
        "        self.target_model=self.build_model()\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "        self.target_update_counter=0\n",
        "        \n",
        "    def build_model(self):\n",
        "        model=Sequential()\n",
        "        model.add(Conv2D(filters=16,kernel_size=(8,8),strides=4,activation='relu',input_shape=(82,80,4)))\n",
        "        model.add(Conv2D(filters=32,kernel_size=(4,4),strides=2,activation='relu',input_shape=(82,80,4)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units=256,activation='relu'))\n",
        "        model.add(Dense(units=env.action_space.n,activation='linear'))\n",
        "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "    \n",
        "    \n",
        "    def remember(self,state,action,reward,next_state,done):\n",
        "        self.memory.append((state,action,reward,next_state,done))\n",
        "    \n",
        "    def act(self,state):\n",
        "#         if np.random.rand() <= self.epsilon:\n",
        "#             return random.randrange(self.action_size)\n",
        "        act_values=self.model.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "        \n",
        "        \n",
        "    def replay(self,batch_size):\n",
        "        minibatch=random.sample(self.memory,batch_size)\n",
        "        \n",
        "        for state,action,reward,next_state,done in minibatch:\n",
        "            target=reward\n",
        "            \n",
        "            if not done:\n",
        "                target=reward+self.gamma*np.amax(self.target_model.predict(next_state)[0])\n",
        "            target_f=self.model.predict(state)\n",
        "            target_f[0][action]=target\n",
        "\n",
        "            self.model.fit(state,target_f,epochs=1,verbose=0)\n",
        "            self.target_update_counter=self.target_update_counter+1\n",
        "            \n",
        "            if self.target_update_counter>=10:\n",
        "                self.update_target_network()\n",
        "                self.target_update_counter=0\n",
        "            \n",
        "        if self.epsilon>self.epsilon_min:\n",
        "            self.epsilon*=self.epsilon_decay\n",
        "    \n",
        "    def update_target_network(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "    def load(self,name):\n",
        "        self.model.load_weights(name)\n",
        "        \n",
        "        \n",
        "    def save(self,name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyJzaJNu1rW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}